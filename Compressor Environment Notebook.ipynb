{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a credit derivatives compressor Open AI Gym environment\n",
    "\n",
    "For my UROP project for the spring 2018 semester, I have created an Open AI Gym environment in an attempt to open the door for open source the problem of using reinforcement learning to build an automatic agent that finds the optimal methodology for compressing a set of derivatives contracts between groups of banks. Given the recent resurgence of financial regulation incentivizing actors within the financial sector to minimize their excess derivative contract notional, devising an artificial intellegence system to automatically minimize this excess over time is certainly a worthwhile endevour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Perhaps I should define the problem I intend to solve, before providing information about the artificial intelligence mechanisms I used to achieve a solution. In this notebook, I attempt to build an OpenAI Gym (a standard format for testing and evaluatiing reinforcement agents' attempts at various problems) that can be used to test a reinforcement learning agent which aims to solve the following problem:\n",
    "\n",
    "First we must define the following notation, a derivatives market can be modelled as consistenting the following elements:\n",
    "\n",
    "1. A set of banks $B$ comprised of banks $(b_0,b_1,\\dots b_n)$\n",
    "1. A set of timesteps $T = (0,1,2,3,4,5,\\dots,n)$, each timestep $t$ represents a week during which derivatives trading occurs.\n",
    "1. A set of edges that comprise a directed graph G, $E = (e_0,e_1, \\dots e_n)$ each edge $e_k =(b_i,b_j)$ of weight $w$ represents an debt owed of $w$ million dollars from bank $b_i$ to bank $b_j$.\n",
    "1. An \"arrival\" of an edge is defined as one of two events:\n",
    "    1. The origination of an edge $e_k =(b_i,b_j)$ that did not exist in prior timesteps.\n",
    "    1. The increase of the weight $w$ of an edge $e_k$ that had existed in prior timesteps.\n",
    "1. The total notional of a derivatives contract graph $G$ is equivalent to:\n",
    "$$\\sum_{\\forall i,j \\in |B|} w(b_i,b_j)$$\n",
    "\n",
    "Where $w(b_i,b_j)$ is a function that returns the weight $w$ of the edge defined as a derivative contract relationship between bank $i$ and bank $j$.\n",
    "\n",
    "Minimizing total notional at a given timestep $t$ is a solved problem, a paper that discusses the impact of solving this problem (derivatives portfolio compression) can be found [here](https://poseidon01.ssrn.com/delivery.php?ID=173022101119066104069084024124124064057072038035075028088075127101004122006005024111124122127028018042026073119104019029013097060013004075058101117086083074115000080085079001122091083005103114006027025067087001080089110082065023117022074089030116069073&EXT=pdf).\n",
    "\n",
    "The precise problem that a intend to allow a reinforcement agent to learn how to solve is this:\n",
    "\n",
    "If edges (derivative contracts) that arrive between banks due to a pattern determined by banks within a given financial system, can an agent to learn minimize notional excess over all periods? In math, this can be formalized as solving for:\n",
    "\n",
    "$$\\min_{t \\in T} \\sum_{\\forall i,j \\in |B|} w_t(b_i,b_j)$$\n",
    "\n",
    "Where $w_t(b_i,b_j)$ is a function that returns the weight $w_t$ of the edge defined as a derivative contract relationship between bank $i$ and bank $j$ at timestep $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Problem\n",
    "\n",
    "The corresponding reinforcement learning problem is very similar to that problem statement above, but with a few simplifications. They are outlined below:\n",
    "\n",
    "1. We will only be attempting to solve for the minimum amongst the top 5 most connected nodes, based on initial analysis, one can see that there are very few very connected nodes, so this is a fair simplification for the more general problem. A histogram is shown below:\n",
    "\n",
    "1. For the early stages of this project, we will only aim to keep total notional below a certain percentage of what I define as counterfactual total notional, which is the total notional that would be observed given no action on a derivatives contract graph $G$, as of right now, this percentage of notional is set at 75%\n",
    "\n",
    "1. To address computational hurdles, all contract originations are normalized by the largest edge that originates during the analyzed time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " #!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Reads total credit data\n",
    "\"\"\"\n",
    "\n",
    "# core modules\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data_to_adj_matrices(path,enddate):\n",
    "    #Loads data from path into dictionary of weeks which map to adjacency matrices representing contracts that originated that week\n",
    "    #Returns week_adj_matrices\n",
    "    derivatives_df = pd.read_csv(path)\n",
    "    derivatives_df = derivatives_df[derivatives_df.Duration != \"ON\"]\n",
    "    derivatives_df = derivatives_df[derivatives_df.Market != \"Market\"]\n",
    "    day_dataframes = dict()\n",
    "    for _,row in derivatives_df.iterrows():\n",
    "        if row.Date in day_dataframes.keys():\n",
    "            day_dataframes[row.Date] = pd.concat([day_dataframes[row.Date],row],axis = 1)\n",
    "        else:\n",
    "            day_dataframes[row.Date] = pd.DataFrame(row)\n",
    "        if row.Date == enddate:\n",
    "            break\n",
    "    BanksList = np.sort(pd.concat([derivatives_df[\"Aggressor\"],derivatives_df[\"Quoter\"]]).unique())\n",
    "    numbanks = len(BanksList)\n",
    "    day_adj_matrices = dict()\n",
    "    week_edges = dict()\n",
    "    week_adj_matrices = dict() \n",
    "    #Initialize array of zeroes for every date\n",
    "    for date in day_dataframes.keys():\n",
    "        day_adj_matrices[date] = np.zeros((numbanks,numbanks))\n",
    "    for endweek in list(day_dataframes.keys())[0:-1:5]:\n",
    "        week_adj_matrices[endweek] = np.zeros((numbanks,numbanks))\n",
    "        week_edges[endweek] = []\n",
    "    for d_i,date in enumerate(day_dataframes.keys()):\n",
    "        if d_i // 5 >= len(list(week_adj_matrices.keys())):\n",
    "            break\n",
    "        endweek = list(week_adj_matrices.keys())[d_i // 5]\n",
    "        \n",
    "        endweekobj = dt.datetime.strptime(endweek, \"%Y-%m-%d\")\n",
    "        for i in day_dataframes[date]:\n",
    "            row = day_dataframes[date][i]\n",
    "            #If the agressor is the lender\n",
    "            a_idx = np.where(BanksList == row.Aggressor)[0][0]\n",
    "            q_idx = np.where(BanksList == row.Quoter)[0][0]\n",
    "            #Check to see if originating contract will not be removed soon\n",
    "            dateobj = dt.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "            \n",
    "            if (row.Duration == 'TN' or row.Duration == 'TNL') and dateobj + dt.timedelta(days = 2) <= endweekobj:\n",
    "                continue\n",
    "            if (row.Duration == 'SN' or row.Duration == 'SNL') and dateobj + dt.timedelta(days = 3) <= endweekobj:\n",
    "                continue\n",
    "            #If the agressor is the lender\n",
    "            if row.Verb == \"Sell\":\n",
    "                #create incidence matrix as well\n",
    "                week_adj_matrices[endweek][q_idx,a_idx] = np.add(float(day_adj_matrices[date][q_idx,a_idx]),int(float(row.Amount)))\n",
    "            #If the agressor is the borrower\n",
    "            if row.Verb == \"Buy\":\n",
    "                week_adj_matrices[endweek][a_idx,q_idx] = np.add(float(day_adj_matrices[date][a_idx,q_idx]),int(float(row.Amount)))\n",
    "    return week_adj_matrices,numbanks\n",
    "\n",
    "def find_most_connected(week_adj_matrices,n_banks):\n",
    "    total_adj_matrix = week_adj_matrices[list(week_adj_matrices.keys())[0]]\n",
    "    for week in list(week_adj_matrices.keys()):\n",
    "        total_adj_matrix += week_adj_matrices[week]\n",
    "\n",
    "    total_contracts = nx.DiGraph()\n",
    "    for i in range(n_banks):\n",
    "        for j in range(n_banks):\n",
    "            if total_adj_matrix[i,j] != 0:\n",
    "                total_contracts.add_edge(i,j,weight=total_adj_matrix[i,j])\n",
    "    deg_centrality_dict = nx.degree_centrality(total_contracts)\n",
    "    return list(deg_centrality_dict.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2850: DtypeWarning: Columns (4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecXVW5//HPFxKkJIKYECEQgtKrXCNdDYKKUkVEvCKgCFIU7ERBRcQL/BSwYQnKDRY6CCg2DHBRqYnSi8SQkNCSAAGiSJHn98daIzuHOeesmcwpk/m+X695zdl1Pbs+e6/dFBGYmZmVWKbTAZiZ2eDhpGFmZsWcNMzMrJiThpmZFXPSMDOzYk4aZmZWrOuShqQ7JU3sdBydJOndkuZIWiRpyzaUN0XSia0upxMkHSTpT5XmRZJe24ZyV5D0S0lPSrqwcJhrJH2kxXGNy/Ng2VaW040knSzpMUlzO1T+zpJmVZrvlfSmTsSyJNqaNCTNkrRzTbvFNuqI2CQirmkynvGSQtKwFoXaad8APhYRIyLir7Ud87TfLmmZSrsTJU1pZ5C5XEk6StIdkv4haa6kCyVtNgDjHvBklufpzFaNv2IfYAzw6oh4b21HScdL+lmLyu7Z1p7JCaLnb42IeCDPg3/3Y5yLbau9dD9R0tSadutLemog1oclIWkd4Chgg4hYs04/q0j6lqQH8vyaIek0Sa9uRUwRsUFE/DGX3XT7zdtWzzJdKOnPkg6VpJLyJK0raYkfzOu6M41u0AXJaG3gzib9rAHs14ZYmvkWcDRpg1wVWB+4FNi11QV3wXJqZG3gbxHxQgdj2D0niJ6/hxr1nA8AlmSf8FXgNZIO6RkfcCZwWkTcvgTjfZl+LPu1gXkRsaDO+JYHrgI2BN4OvBLYDngKmDAA5Q+Ud0bECGA88HXgC8DktkYQEW37A2YBO9e0Owj4U2/9AFsB00gL7lHSygfwABDAovy3LSkBHgfMBuYBPwFWroz3gNztMeCLNeUcD1wE/CyX9ZFc9vXAQuBh4LvAcpXxBXAEcB/wNGmDeR1wXR7HBdX+a6a511iBV+TpCeAfwN/rDB/AMbnsYbndicCUSj97kBLPQuAaYKNKty2Bv+S4zwfOA06sdN8NuCUPex2weZ041gP+DWzVYJm/gnTm9EBehj8AVsjdJgJzgU/n+fAw8KHc7VDgeeC5PE9+WVk/jgFuA54FhgGTgL/n6bkLeHeD9SuAdXsbP/BZ4OKa+L8NfKvOtG2U5+3CPK/3yO2/ksf7fB73wTXD7VLT/dbc/pq8Hv05T8vvgVGV4bbJy2MhcCswsS/bWm4/Ps+DYZUyv5bLfCbPm4OAmTmG+4EP5Gn9V17ei4CFdcrdmrSNrQF8NC+n4ZXuHwHuAZ4AfgOsVen23bw+PAXcDGxX6XYiaV09N8d1UC9lr0Lahufn6f88oDy/nwFezLH/qJdhDwMeAlZsME/n5nXkduDZ3G5N4Be5zPuBIyv9rwj8NE/rnaT1dlbN+CaStrfq+jC9QfkTa9ptm6drw8p2f0uehw8AX6z0+xCL7zffSNqGrwYeBxbkeFeuNw8iouuTxvXAB/PvEcA2va34ud2HgRnAa3O/lwA/zd02zjNpB2A50k7seRZPGs8De5F26CsAbyBtpMNyeXcDn6jZ+VxGOiLZhLQDm5rLX5m08zqwznyoG2t1x9ZgPkZe2NOBj1Q2qin59/qkpPM2YDjwuVzecvlvNvDJ3G2fPO0n5mG3JO3AtwaWBQ7My+QVdTa02U2W+enA5aSzkJGknfNJudtE4AXghBzLu4B/Aq/K3adQSWaV9eMWYC1eSj7vJe2klgHel6d99Trr13/mbe34gdXzsKvk5mF5Xryhl+kanufpF/I8fStpZ7ZBZZ36WYP58rLupB343/PyWyE3n5y7jSXtjN+Vp/NtuXl06bbW27aTy3iAtA4PI627T1WmY3Vgk97mZYNpO5W0LSwAJlTavwe4F9ggl3U88MdK9w/m9WQYaQf7IHm9I63fzwG75+lfoZdyzyFtSyNJ29YM8jYI7Exlh93LsBcBP24yXXNJ29yaefksQ1oXe9aBdfN83yn3/408f19FOtO5i16SRu3226T8ib20fwg4JP9+a16WywBb5GWwW+62LhA1w64P7JTjX4108PCNhnE0WwEG8i/P0EWkI6Wev39SP2lcSzpqG1UznsVW/NxuKnBEpXkD0s5wGPAl4NxKtxXzClhNGtc2if0TwC8qzQFsX2meDhxTs+F8s8646sZaGXezpLEuaQcyOy/watL4InBBpf9lSBvgRODNeSVTpft1vJQ0vg98taa8e4G39BLHscANDeIUaSf8ukq7bYH78++JpCPA6nKcx0sHB1PoPWl8uMmyugXYM/8+iMKkkdv9hpc2wN2Au+qU8SbgEWCZSrtzgeMr61R/ksZxleYjgN/m38dQObDI7X5H/QOTWSy+rV3a27aTyzyhMtxKuf/3ULNjrp2XDaZthbxenl7T/spqvKRt81lgbJ1152leSlgnAlc1KHM46QBk/Uq7I4E/5N/NksbVtetCL/3MBQ6oNG8PzKzp54vAmfn3A1QSd16es2rGN7EyfVMKyp/YS/tpVPY9Nd2+C3w9/35Z0uil/32Amxv104lrGntFxCo9f6QZWc/BpEx4j6SbJe3WoN81SCtqj9mklXJM7janp0NE/JN0lFY1p9qQL+D9StIjkp4C/gcYVTPMo5Xfz/TSPKIfsRaLiF+TVqSPNhp/RLxImr6xuduDkdeQSvk91gY+nS+0LZS0kHRUv0YvITxGOhKtZzQpQU+vjOu3uf1/xhGL1/v/k/rzrUftsjpA0i2VMjbl5cuq1NnA/vn3/qTT9d6sAczJ87bHbNI8XhKPVH5X58XawHtrlssONJ7/1W1trwb9VbeNf5DO1g4DHpZ0haQN+zIBEfEMqaqm9rrc2sAZlfgXkKpW1gSQ9DlJ90h6klSlsxKLL8c51Lca6cy4drsqXR7N1uXeYlgbGFezTD4HvCZ3X72m/2psA2ksqXoJSdvmu/Dm5/n4ERpsC5JeI+kCSQ/m/dyURv1Dl18Ij4j7IuL9pBXiFOAiSSuRjpRqPURaiD3GkY48HiXVlf/njglJKwC1d0TUjvP7pLrX9SLilaRT0KK7FAo0irWvjiXFtmK98ecLkmuRzjYeBsbW3HExrvJ7DvC1amKPiBUj4txeyp4KrCnpZRcKswWk5LlJZVwrR7qQV6K35bxYe0lrky62fox0p9IqwB2ULavexn8psLmkTUlnGj+vM+xDwFo1F47HkeZxiXrTVs8c0plGdbmsFBEn93E8TWOJiN9FxNtIO717SPP3Zf31wxzS9Z3qNKwQETdK2hH4FOkMZxVSlc4iFl+OjcqfR7reUrtdlS6PPwDvzPuGRqoxzAHuq5mekRGxe+7+CGm7q8ZTMt5ikrYhHWz23NV2HnAx6VrRysCPeGke9lbGKaSzvc3yfu4gmmw7XZ00JO0vaXQ+mluYW79Iuuj0Iqnesse5wCclrSNpBOnM4Px8FHsRsLuk7SQtR6oaaLZTGUmq212Uj7QOH6jpahJrn0S6PfkO0rWHHhcAu0raSdJw0oXmZ0nVUNeTEtRRkoZL2pt00b/HmcBhkrbOd9OsJGlXSSN7Kfs+4HvAuZImSlpO0vKS9pM0KS+3M4HTJa0GIGmspHcUTt6jLL6Me9NzEDE/j/9DpDONfo0/Iv5FWl/OAW6KiAfqDHsj6Uzgc3k+TiTVt5/Xh7LH9+FupZ+R1uF3SFo2z+eJknq9fbS/JI2RtGc+OHuWtOPuOZt6lHSQsFw/R/8D4FhJG+WyVpG0T+42krReLiBVNR1PWrZFIuJ50nL7H0kjlG6x/SRpvpWYQtrJXyxpg7zuj5L0xQbr6/XAc5I+nZfHspI2k/SG3P0C4At5OseRDmzq6VkfSm+fXVnSHqT1dEpE3J07jQQej4h/5YRSvcNyHhBa/DmlkaQq5CclrQV8plnZXZ00SHc93ClpEenWzv0i4plcvfQ14M/5tHAb4CxSVcK1pFPjfwEfB4iIO/Pv80hH2otIM/DZBmV/BvhvUr3qmaQ7NwZK3Vj76TjSBUQAIuJeUtXKd0gb4e6k2y+fi4jngL1JRxSPk6oiLqkMOw04hFQX+gTpYuJBDco+Kvd7Bimx/x14N+mCN6S6+BnADfn09w+kazglfgxsnJfxpb31EBF3ka4fXU/a8DYjXcxbkvGfncdTr2qKPB93B95JmsffI9V331NYds8Df49J+kuzniNiDrAn6axyPuko97MM/Da8DOmI/yHS+vEWXjpguopU5fSIpF5vXW0kIi4ETgMuzOvCbUDPDvnXpHXjPtL1mKdI22pfHEG6VjkL+D/ScvxJYWz/Il1EnpHjeBq4gXRjwM11hnmBdF1xq1zmAuCHpJtjAL6cp2EW6VpZo1jOJ12bfFzSTQ36+03eHz5Aumvw66QqqB6HAydJepq0rlxQifdp4CTgxrzOT8gxbgU8Sbph5eIGZQP5YuhQk4/uF5Kqnu7vdDzWXfJR4T3AayLiqU7HY9ZNuv1MY8BI2l3Sivm0+xuke61ndTYq6za5uuhTwHlOGGYv181P1A60PUnVDSLdorZfDMXTLKsrH1A8SrrLZZcOh2PWlYZk9ZSZmfXPkKmeMjOzJTcoqqdGjRoV48eP73QYZmaDyvTp0xdExOjmfZYbFElj/PjxTJs2rdNhmJkNKpIG/Cl0V0+ZmVkxJw0zMyvmpGFmZsWcNMzMrJiThpmZFXPSMDOzYk4aZmZWzEnDzMyKOWmYmVmxQfFE+JIYP+mKjpQ76+RdO1KumVkrtTRpSJpF+gLWv4EXImKCpFVJX6kaT/qexb4R8UQr4zAzs4HRjuqpHSPi9RExITdPAqZGxHrA1NxsZmaDQCeuaexJ+nYv+f9eHYjBzMz6odVJI4DfS5ou6dDcbkxE9Hww/hFgTG8DSjpU0jRJ0+bPn9/iMM3MrESrL4TvEBEPSloNuFLSPdWOERGSev10YERMBiYDTJgwwZ8XNDPrAi0904iIB/P/ecAvgK2ARyWtDpD/z2tlDGZmNnBaljQkrSRpZM9v4O3AHcDlwIG5twOBy1oVg5mZDaxWVk+NAX4hqaeccyLit5JuBi6QdDAwG9i3hTGYmdkAalnSiIiZwBa9tH8M2KlV5ZqZWev4NSJmZlbMScPMzIo5aZiZWTEnDTMzK+akYWZmxZw0zMysmJOGmZkVc9IwM7NiThpmZlbMScPMzIo5aZiZWTEnDTMzK+akYWZmxZw0zMysmJOGmZkVc9IwM7NiThpmZlbMScPMzIq18hvhQ9r4SVd0rOxZJ+/asbLNbOnmMw0zMyvmpGFmZsWcNMzMrJiThpmZFXPSMDOzYk4aZmZWzEnDzMyKOWmYmVkxJw0zMyvmpGFmZsWcNMzMrJiThpmZFWt50pC0rKS/SvpVbl5H0o2SZkg6X9JyrY7BzMwGRjvONI4G7q40nwKcHhHrAk8AB7chBjMzGwAtTRqS1gR2BX6UmwW8Fbgo93I2sFcrYzAzs4HT6jONbwKfA17Mza8GFkbEC7l5LjC2twElHSppmqRp8+fPb3GYZmZWomVJQ9JuwLyImN6f4SNickRMiIgJo0ePHuDozMysP1r55b7tgT0kvQtYHngl8C1gFUnD8tnGmsCDLYzBzMwGUMvONCLi8xGxZkSMB/YDroqIDwBXA/vk3g4ELmtVDGZmNrA68ZzGMcCnJM0gXeP4cQdiMDOzfmhaPSVpOnAWcE5EPNGfQiLiGuCa/HsmsFV/xmNmZp1VcqbxPmAN4GZJ50l6R7511szMhpimSSMiZkTEscD6wDmks47Zkr4iadVWB2hmZt2j6JqGpM2BU4GvAxcD7wWeAq5qXWhmZtZtSq9pLCRdsJ4UEc/mTjdK2r6VwZmZWXcpeU7jvfni9X9IWici7o+IvVsUl5mZdaGS6qmLCtuZmdlSru6ZhqQNgU2AlSVVzyheSXrC28zMhphG1VMbALsBqwC7V9o/DRzSyqDMzKw71U0aEXEZcJmkbSPi+jbGZGZmXapR9dTnIuL/Af8t6f213SPiqJZGZmZmXadR9VTP1/amtSMQMzPrfo2qp36Zf94eEX9pUzxmZtbFSm65PVXS3ZK+KmnTlkdkZmZdq+TdUzsCOwLzgR9Kul3ScS2PzMzMuk7Ru6ci4pGI+DZwGHAL8KWWRmVmZl2padKQtJGk4yXdDnwHuI70mVYzMxtiSt49dRZwPvCOiHioxfGYmVkXa5o0ImLbdgRiZmbdr9HDfRdExL65WiqqnYCIiM1bHp2ZmXWVRmcaR+f/u7UjEDMz6351L4RHxMP55xERMbv6BxzRnvDMzKyblNxy+7Ze2r1zoAMxM7Pu1+iaxuGkM4rXSbqt0mkk6bZbMzMbYhpd0zgH+A1wEjCp0v7piHi8pVHZoDR+0hUdK3vWybt2rGyzoaTRNY0nI2IW8C3g8cr1jBckbd2uAM3MrHuUXNP4PrCo0rwotzMzsyGmJGkoIv7znEZEvEjZk+RmZraUKUkaMyUdJWl4/jsamNnqwMzMrPuUJI3DgO2AB4G5wNbAoa0MyszMulPJu6fmAfu1IRYzM+tyJa9GX1/SVEl35ObN/REmM7OhqaR66kzg88DzABFxGz7zMDMbkkqSxooRcVNNuxeaDSRpeUk3SbpV0p2SvpLbryPpRkkzJJ0vabn+BG5mZu1XkjQWSHod+fXokvYBHm48CADPAm+NiC2A1wO7SNoGOAU4PSLWBZ4ADu5X5GZm1nYlSeNI4IfAhpIeBD4BHN5soEh6Hgocnv8CeCtwUW5/NrBXX4M2M7POKLl7aiaws6SVgGUi4unSkUtaFpgOrAucAfwdWBgRPdVbc4GxdYY9lHxr77hx40qLNDr7DigzW7o1TRqSXgG8BxgPDJMEQESc0GzYiPg38HpJqwC/ADYsDSwiJgOTASZMmBBNejczszYoeR3IZcCTpDOGZ/tTSEQslHQ1sC2wiqRh+WxjTdJDg2ZmNgiUJI01I2KXvo5Y0mjg+ZwwViB9zOkU4GpgH+A84EBSUjIzs0Gg5EL4dZI268e4Vweuzh9wuhm4MiJ+BRwDfErSDODVwI/7MW4zM+uAkjONHYCDJN1Pqp4S6eaozRsNlB8C3LKX9jOBrfoRq5mZdVhJ0vD3wM3MDCi75XZ2vnV2TEn/Zma29Cq55fbjwJeBR4EXc+sAGlZPmZnZ0qfkzOFoYIOIeKzVwZiZWXcruXtqDuk5DTMzG+JKzjRmAtdIuoLKw30RcVrLojIzs65UkjQeyH/L5T8zMxuiSu6e6vkOxojcvKjxEGZmtrQq+dzrppL+CtwJ3ClpuqRNWh+amZl1m5IL4ZOBT0XE2hGxNvBp0idgzcxsiClJGitFxNU9DRFxDbBSyyIyM7OuVXT3lKQvAj/NzfuT7qgyM7MhpuRM48PAaOAS4GJgVG5nZmZDTN0zDUnLAyMjYj5wVKX9GOCZNsRmZmZdptGZxreBN/XSfmfg9NaEY2Zm3axR0tghIi6pbRkRPwfe3LqQzMysWzVKGurncGZmtpRqtPOfJ+llX9iT9EZgfutCMjOzbtXoltvPAhdImgJMz+0mAAcA+7U4LjMz60J1zzQi4ibSt7wFHJT/BGwdETe2IzgzM+suDR/ui4h5pK/2mZmZ+YK2mZmVc9IwM7NixUlD0oqtDMTMzLpfyfc0tpN0F3BPbt5C0vdaHpmZmXWdkjON04F3AI8BRMSt+IlwM7Mhqah6KiLm1LT6dwtiMTOzLlfyPY05krYDQtJw4Gjg7taGZWZm3ajkTOMw4EhgLPAg8PrcbGZmQ0zTM42IWAB8oA2xmJlZlyu5e2p9SVMl3ZGbN5d0XOtDMzOzblNSPXUm8HngeYCIuI2CFxZKWkvS1ZLuknSnpKNz+1UlXSnpvvz/VUsyAWZm1j4lSWPF/PLCqhcKhnsB+HREbAxsAxwpaWNgEjA1ItYDpuZmMzMbBEqSxgJJrwMCQNI+wMPNBoqIhyPiL/n306Q7rsYCewJn597OBvbqR9xmZtYBJbfcHglMBjaU9CBwP328MC5pPLAlcCMwJiJ6ks4jwJi+jMvMzDqnYdKQtAwwISJ2lrQSsEw+aygmaQRwMfCJiHhKeukrshERkqLOcIcChwKMGzeuL0WamVmLNKyeiogXgY/l3//oR8IYTkoYP4+IS3LrRyWtnruvDsyrU/bkiJgQERNGjx7dl2LNzKxFSq5pXCnpM/luqFV7/poNpHRK8WPg7og4rdLpcuDA/PtA4LI+R21mZh1Rck3jw/l/9SnwAF7bZLjtgQ8Ct0u6Jbf7AnAy6dvjBwOzgX3LwzUzs04qeSJ8nf6MOCL+RPqmeG926s84zcyss5omDUl799L6SeD2/A1xMzMbIkqqpw4GtgWuzs0TgRuA9SWdEBE/bVFsZmbWZUqSxovARhHxKICkMcD3gK2BawEnDTOzIaLk7qnxPQkjmwdsEBGPk99HZWZmQ0PJmcYfJf0KuDA37wNcmx/2W9iyyMzMrOuUvkZkb2CH3Hw2cHFEBLBjqwIzM7PuU3LLbUiaBjwZEX+QtCIwAujT0+FmZjb4lXyE6RDgIuCHudVY4NJWBmVmZt2p5EL4kaSnu58CiIj7gNVaGZSZmXWnkqTxbEQ819MgaRj52xpmZja0lCSN/5P0BWAFSW8j3UX1y9aGZWZm3agkaUwC5gO3Ax8Ffg0c18qgzMysO5XcPfWipEuBSyNifhtiMjOzLlX3TEPJ8ZIWAPcC90qaL+lL7QvPzMy6SaPqqU+S7pp6Y0SsGhGrkt43tb2kT7YlOjMz6yqNksYHgfdHxP09LSJiJrA/cECrAzMzs+7TKGkMj4gFtS3zdY3hrQvJzMy6VaOk8Vw/u5mZ2VKq0d1TW0h6qpf2ApZvUTxmZtbF6iaNiFi2nYGYmVn3K3m4z8zMDHDSMDOzPnDSMDOzYiVf7jPreuMnXdGRcmedvGtHyjXrFJ9pmJlZMScNMzMr5qRhZmbFnDTMzKyYk4aZmRVz0jAzs2JOGmZmVszPaZgNUn42xTqhZWcaks6SNE/SHZV2q0q6UtJ9+f+rWlW+mZkNvFZWT00BdqlpNwmYGhHrAVNzs5mZDRItSxoRcS3weE3rPYGz8++zgb1aVb6ZmQ28dl8IHxMRD+ffjwBj6vUo6VBJ0yRNmz9/fnuiMzOzhjp291REBBANuk+OiAkRMWH06NFtjMzMzOppd9J4VNLqAPn/vDaXb2ZmS6DdSeNy4MD8+0DgsjaXb2ZmS6Blz2lIOheYCIySNBf4MnAycIGkg4HZwL6tKt+sHTr1rEQndXKa/YxI57UsaUTE++t02qlVZZqZWWv5NSJmZlbMScPMzIr53VNmNmj4fVud5zMNMzMr5qRhZmbFnDTMzKyYk4aZmRVz0jAzs2JOGmZmVsxJw8zMivk5DTOzJvx8yEt8pmFmZsWcNMzMrJiThpmZFXPSMDOzYk4aZmZWzEnDzMyKOWmYmVkxJw0zMyvmpGFmZsWcNMzMrJiThpmZFXPSMDOzYk4aZmZWzEnDzMyKOWmYmVkxJw0zMyvmpGFmZsWcNMzMrJiThpmZFXPSMDOzYk4aZmZWrCNJQ9Iuku6VNEPSpE7EYGZmfdf2pCFpWeAM4J3AxsD7JW3c7jjMzKzvOnGmsRUwIyJmRsRzwHnAnh2Iw8zM+mhYB8ocC8ypNM8Ftq7tSdKhwKG5cZGke/tR1ihgQT+G6yaDfRoGe/zgaegWg30a+hy/TlniMtde4jHU6ETSKBIRk4HJSzIOSdMiYsIAhdQRg30aBnv84GnoFoN9GgZ7/D06UT31ILBWpXnN3M7MzLpcJ5LGzcB6ktaRtBywH3B5B+IwM7M+anv1VES8IOljwO+AZYGzIuLOFhW3RNVbXWKwT8Ngjx88Dd1isE/DYI8fAEVEp2MwM7NBwk+Em5lZMScNMzMrtlQkjWavJZH0Cknn5+43Shrf/ijrK4j/U5LuknSbpKmSBvze6yVV+moYSe+RFJK67tbDkmmQtG9eFndKOqfdMTZTsC6Nk3S1pL/m9eldnYizHklnSZon6Y463SXp23n6bpP0X+2OsZGC+D+Q475d0nWStmh3jEssIgb1H+li+t+B1wLLAbcCG9f0cwTwg/x7P+D8Tsfdx/h3BFbMvw/vpvhLpyH3NxK4FrgBmNDpuPuxHNYD/gq8Kjev1um4+zENk4HD8++NgVmdjrsmvjcD/wXcUaf7u4DfAAK2AW7sdMx9jH+7yvrzzm6Lv+RvaTjTKHktyZ7A2fn3RcBOktTGGBtpGn9EXB0R/8yNN5Cebekmpa+G+SpwCvCvdgZXqGQaDgHOiIgnACJiXptjbKZkGgJ4Zf69MvBQG+NrKiKuBR5v0MuewE8iuQFYRdLq7YmuuWbxR8R1PesP3bktN7U0JI3eXksytl4/EfEC8CTw6rZE11xJ/FUHk460uknTacjVCGtFxBXtDKwPSpbD+sD6kv4s6QZJu7QtujIl03A8sL+kucCvgY+3J7QB09ftpZt147bcVNe+RsReTtL+wATgLZ2OpS8kLQOcBhzU4VCW1DBSFdVE0hHitZI2i4iFHY2qb94PTImIUyVtC/xU0qYR8WKnAxtKJO1ISho7dDqWvloazjRKXkvyn34kDSOdlj/WluiaK3qtiqSdgWOBPSLi2TbFVqrZNIwENgWukTSLVBd9eZddDC9ZDnOByyPi+Yi4H/gbKYl0i5JpOBi4ACAirgeWJ71Ib7AY9K8hkrQ58CNgz4jolv1QsaUhaZS8luRy4MD8ex/gqshXorpA0/glbQn8kJQwuq0eHZpMQ0Q8GRGjImJ8RIwn1eXuERHTOhNur0rWo0tJZxlIGkWqrprZziCbKJmGB4CdACRtREoa89sa5ZK5HDgg30W1DfBkRDzc6aBKSRoHXAJ8MCL+1ul4+qXTV+IH4o90R8XfSHeOHJvbnUDaMUHaMC4EZgA3Aa/tdMx9jP8PwKPALfnv8k7H3NdpqOn3Grrs7qnC5SBSNdtdwO3Afp2OuR/TsDHwZ9KdVbcAb+90zDXxnws8DDxPOrM7GDgMOKyyDM7I03d7t61HBfH/CHhfL0IpAAAB7ElEQVSisi1P63TMff3za0TMzKzY0lA9ZWZmbeKkYWZmxZw0zMysmJOGmZkVc9IwM7NiThpmQH7z7qmV5s9IOr6P41g04IGZdRknDbPkWWDv/NCemdXhpGGWvEB6bfgnaztIGi/pqsr3TMbl9utIul7SzZK+WjPMZ3P72yR9JbdbSdIVkm6VdIek97VjwswGkpOG2UvOAD4gaeWa9t8Bzo6IzYGfA9/O7b8FfD8i3gg80tOzpLeT3km1FfB64A2S3gzsAjwUEVtExKbAb1s6NWYt4CfCzUjXIyJihKQTSK+AeAYYERHHS1oArB4Rz0saDjwcEaMkPQa8Jrd/JSkhjJD0DdI7znrefjsCOAn4I/B74HzgVxHxxzZPptkS86vRzRb3TeAvwP8W9t/bUZeAkyLihy/rkL4r8i7gJEm/j4gT+h2pWQe4esqsIiIeJ706/OBK6+tIb4wF+ADpjAHSi/+q7Xv8DviwpBEAksZKWk3SGsA/I+JnwDdInwU1G1R8pmH2cqcCH6s0fxz4X0mfJb1G/EO5/dHAOZKOBi7u6Tkifp9fO359/qrwImB/YF3g65JeJFWBHd7qCTEbaL6mYWZmxVw9ZWZmxZw0zMysmJOGmZkVc9IwM7NiThpmZlbMScPMzIo5aZiZWbH/D73m9wZuqaMRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2958ee5df60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "week_adj_matrices_all,n = load_data_to_adj_matrices('C:\\Python36\\Lib\\site-packages\\gym\\envs\\gym_compressor\\complete_credit_data.csv','2000-01-05')\n",
    "plt.hist(find_most_connected(week_adj_matrices_all,n))\n",
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Degree Connectivity')\n",
    "plt.title('Histogram of Node Centrality of the First Year of Credit Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Structure\n",
    "\n",
    "The reward structure of this problem is quite simple, our agent will recieve a reward of $-1$ for every time step it spends with total notional above the given threshold and positive 1 otherwise. Below is the \"\\_get\\_reward\" fucntion in our OpenAi Gym environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_reward(self):\n",
    "        \"\"\"Reward is given for each timestep below the is_compressed threshold.\"\"\"\n",
    "        if self.is_compressed:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Structure\n",
    "\n",
    "As previously mentioned, minimizing the total notional amongst a set of banks $B$ and their respective edges $E$ while maintaining the amount owed from each bank to every other is a solved problem. It can be solved using the following linear programming problem:\n",
    "\n",
    "\\begin{equation} \\label{eq1}\n",
    "\\begin{split}\n",
    "\\text{minimize } & \\hat{u} \\cdot e' \\\\\n",
    "\\text{subject to } & Qe' = v \\\\\n",
    "& 0 \\leq e' \\leq e\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\hat{u}$ is a vector of all 1's $e'$ is the set of edges that would minimize total notional $Q$ is an incidence matrix of our derivatives contract graph $G$ and $v$ is a vector representation of the total degree of each bank (which represents underlying value on each banks balance sheet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Structure\n",
    "\n",
    "### State Observations\n",
    "\n",
    "The observation structure is a bit more complicated, the agent observes the state it exists in which is the culmination of action its taken, and contracts that have arrived during during the current episode. After it make a specific action, the agent sees an adjacency matrix repesenting derivatives contracts that have originated up to timestep $t$ between the top $n$ banks with the highest node centrality. As an adjacency matrix is a very noisy way to view and try to discern patterns within a derivatives contract graph, I have looked quite seriously into using the first $k$ singular values of the adjacency matrix to derive a rank $k$ representation of the adjacency matrix.\n",
    "\n",
    "### Action Observations\n",
    "\n",
    "In addition, the agent observes the critical cycles of the adjacency matrix representing the culmination of derivatives contracts up to timestep $t$, these critical cycles are calculated by utilizing a conservative compression linear programming algorithm to find the graph that minimizes the notional excess of our derivatives contract graph. I then subtract this graph from the \"current adjacency matrix\" as described in \"State Observations\". The cycles of this graph consist entirely of \"critical cycles\" or cycles that be removed in order to miniminze excess notional in the derivatives contract graph. Given $n$ critical cycles, our agent can choose between action $ 0 < i \\leq n$ where choosing action $i$ runs the following algorithm, as described in (D’Errico and Roukny 2018):\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_critical_cycle(ccycle,adj_matrix):\n",
    "    path = ccycle['cycle']\n",
    "    path_edges = [(path[i-1],path[i]) for i in range(1,len(path))]\n",
    "    min_edge = min([adj_matrix[edge] for edge in path_edges])\n",
    "    for edge in path_edges:\n",
    "        adj_matrix[edge] = adj_matrix[edge] - min_edge\n",
    "    return adj_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Observation\n",
    "\n",
    "THe last observation to touch on is the observation that allows the agent to best discern how close it is to an optimal reward. Every timestep, our agent recieved information stating its excess\\_percent which is the percent of counterfactual notional that is currently achieved by the current adjacency matrix. This is the same metric that will decide if an agent will recieve a reward of positive or negative 1 during a given timestep.\n",
    "\n",
    "\\_get\\_state logic is displayed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _get_state(self):\n",
    "        \"\"\"Get the observation.\"\"\"\n",
    "        self.counterfactual_adj_matrix = self.counterfactual_adj_matrix + self.week_adj_matrices[self.curr_date]\n",
    "        self.curr_adj_matrix = self.curr_adj_matrix + self.week_adj_matrices[self.curr_date]\n",
    "        excess_percent = np.sum(self.curr_adj_matrix)/np.sum(self.counterfactual_adj_matrix)\n",
    "        compress_res = compress_data(self.curr_adj_matrix)\n",
    "        critical_matrix = compress_res[\"critical_matrix\"]\n",
    "        compressed_matrix = self.curr_adj_matrix - critical_matrix\n",
    "        self.ccycles = critical_list_from_matrix(critical_matrix)\n",
    "        return dict({\"curr_adj_matrix\":normalize_matrix(self.curr_adj_matrix),\n",
    "                    \"compressed_matrix\":normalize_matrix(compressed_matrix),\n",
    "                    \"excess_percent\":excess_percent})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "1. Build a deep learning agent to play in this model, right now the cross entropy agent from the OpenAI Gym package that I am using has quite poor performance; I made this gym enviroment to test architectures with stronger pattern recognition abilities, and I certainly would like to test my environment on such architectures.\n",
    "1. I have been playing quite a bit with the idea of sending the reinforcement learning agent information about only portions of the singular value decompisition of the \"current state adjacency matrix\". This would help accentuate patterns within the adjacency matrix amongst banks with very distinct trading patterns. Once I am able to begin to work more seriously on using a deep learning architecture for policy discovery this will definitly be the first mutation of the very noisy adjacency matrix I will try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_policies'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-22ab18b6da70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0m_policies\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBinaryActionLinearPolicy\u001b[0m \u001b[1;31m# Different file so it can be unpickled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '_policies'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "from gym import wrappers, logger\n",
    "import numpy as np\n",
    "from six.moves import cPickle as pickle\n",
    "import json, sys, os\n",
    "from os import path\n",
    "from _policies import BinaryActionLinearPolicy # Different file so it can be unpickled\n",
    "import argparse\n",
    "\n",
    "def cem(f, th_mean, batch_size, n_iter, elite_frac, initial_std=1.0):\n",
    "    \"\"\"\n",
    "    Generic implementation of the cross-entropy method for maximizing a black-box function\n",
    "\n",
    "    f: a function mapping from vector -> scalar\n",
    "    th_mean: initial mean over input distribution\n",
    "    batch_size: number of samples of theta to evaluate per batch\n",
    "    n_iter: number of batches\n",
    "    elite_frac: each batch, select this fraction of the top-performing samples\n",
    "    initial_std: initial standard deviation over parameter vectors\n",
    "    \"\"\"\n",
    "    n_elite = int(np.round(batch_size*elite_frac))\n",
    "    th_std = np.ones_like(th_mean) * initial_std\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        ths = np.array([th_mean + dth for dth in  th_std[None,:]*np.random.randn(batch_size, th_mean.size)])\n",
    "        ys = np.array([f(th) for th in ths])\n",
    "        elite_inds = ys.argsort()[::-1][:n_elite]\n",
    "        elite_ths = ths[elite_inds]\n",
    "        th_mean = elite_ths.mean(axis=0)\n",
    "        th_std = elite_ths.std(axis=0)\n",
    "        yield {'ys' : ys, 'theta_mean' : th_mean, 'y_mean' : ys.mean()}\n",
    "\n",
    "def do_rollout(agent, env, num_steps, render=False):\n",
    "    total_rew = 0\n",
    "    ob = env.reset()\n",
    "    for t in range(num_steps):\n",
    "        a = agent.act(ob)\n",
    "        (ob, reward, done, _info) = env.step(a)\n",
    "        total_rew += reward\n",
    "        if render and t%3==0: env.render()\n",
    "        if done: break\n",
    "    return total_rew, t+1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logger.set_level(logger.INFO)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--display', action='store_true')\n",
    "    parser.add_argument('target', nargs=\"?\", default=\"CartPole-v0\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    env = gym.make(args.target)\n",
    "    env.seed(0)\n",
    "    np.random.seed(0)\n",
    "    params = dict(n_iter=10, batch_size=25, elite_frac = 0.2)\n",
    "    num_steps = 200\n",
    "\n",
    "    # You provide the directory to write to (can be an existing\n",
    "    # directory, but can't contain previous monitor results. You can\n",
    "    # also dump to a tempdir if you'd like: tempfile.mkdtemp().\n",
    "    outdir = '/tmp/cem-agent-results'\n",
    "    env = wrappers.Monitor(env, outdir, force=True)\n",
    "\n",
    "    # Prepare snapshotting\n",
    "    # ----------------------------------------\n",
    "    def writefile(fname, s):\n",
    "        with open(path.join(outdir, fname), 'w') as fh: fh.write(s)\n",
    "    info = {}\n",
    "    info['params'] = params\n",
    "    info['argv'] = sys.argv\n",
    "    info['env_id'] = env.spec.id\n",
    "    # ------------------------------------------\n",
    "\n",
    "    def noisy_evaluation(theta):\n",
    "        agent = BinaryActionLinearPolicy(theta)\n",
    "        rew, T = do_rollout(agent, env, num_steps)\n",
    "        return rew\n",
    "\n",
    "    # Train the agent, and snapshot each stage\n",
    "    for (i, iterdata) in enumerate(\n",
    "        cem(noisy_evaluation, np.zeros(env.observation_space.shape[0]+1), **params)):\n",
    "        print('Iteration %2i. Episode mean reward: %7.3f'%(i, iterdata['y_mean']))\n",
    "        agent = BinaryActionLinearPolicy(iterdata['theta_mean'])\n",
    "        if args.display: do_rollout(agent, env, 200, render=True)\n",
    "        writefile('agent-%.4i.pkl'%i, str(pickle.dumps(agent, -1)))\n",
    "\n",
    "    # Write out the env at the end so we store the parameters of this\n",
    "    # environment.\n",
    "    writefile('info.json', json.dumps(info))\n",
    "\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
